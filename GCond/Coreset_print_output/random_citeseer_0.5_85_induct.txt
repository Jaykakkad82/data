Namespace(dataset='citeseer', epochs=400, gpu_id=0, hidden=256, inductive=1, keep_ratio=1.0, lr=0.01, method='random', nlayers=2, normalize_features=True, reduction_rate=0.5, save=1, seed=85, weight_decay=0.0005)
size of adj_train: (120, 120)
#edges in adj_train: 16.0
Test set results: loss= 0.5460 accuracy= 0.8470
Mean accuracy: [0.6452, 0.007871467461661777]
Namespace(dataset='citeseer', epochs=400, gpu_id=0, hidden=256, inductive=1, keep_ratio=1.0, lr=0.01, method='random', nlayers=2, normalize_features=True, reduction_rate=0.5, save=1, seed=85, weight_decay=0.0005)
size of adj_train: (120, 120)
#edges in adj_train: 16.0
Test set results: loss= 0.5460 accuracy= 0.8470
Mean accuracy: [0.6452, 0.007871467461661777]
Namespace(dataset='citeseer', epochs=400, gpu_id=0, hidden=256, inductive=1, keep_ratio=1.0, lr=0.01, method='random', nlayers=2, normalize_features=True, reduction_rate=0.5, save=1, seed=85, weight_decay=0.0005)
size of adj_train: (120, 120)
#edges in adj_train: 16.0
Test set results: loss= 0.8314 accuracy= 0.7910
idx_selected :  [array([ 49, 100,   6,  77,  35,  66,  38,  61,  39,   4]), array([104,  55, 102,  65,  99,  71,  41,  81,  43,  13]), array([ 3, 33, 37, 73, 90, 26,  9, 22, 24, 52]), array([111,   7, 114, 117, 107, 112,  76, 109, 115, 110]), array([60, 69, 40, 59, 75, 31, 42, 53, 48, 25]), array([17, 28, 68, 58, 56, 92, 11, 18, 36, 83])]
Mean accuracy: [0.6438, 0.00802246844805264]
Namespace(dataset='citeseer', epochs=400, gpu_id=0, hidden=256, inductive=1, keep_ratio=1.0, lr=0.01, method='random', nlayers=2, normalize_features=True, reduction_rate=0.5, save=1, seed=85, weight_decay=0.0005)
size of adj_train: (120, 120)
#edges in adj_train: 16.0
Test set results: loss= 0.8314 accuracy= 0.7910
idx_selected :  [array([ 49, 100,   6,  77,  35,  66,  38,  61,  39,   4]), array([104,  55, 102,  65,  99,  71,  41,  81,  43,  13]), array([ 3, 33, 37, 73, 90, 26,  9, 22, 24, 52]), array([111,   7, 114, 117, 107, 112,  76, 109, 115, 110]), array([60, 69, 40, 59, 75, 31, 42, 53, 48, 25]), array([17, 28, 68, 58, 56, 92, 11, 18, 36, 83])]
Mean accuracy: [0.6438, 0.00802246844805264]
