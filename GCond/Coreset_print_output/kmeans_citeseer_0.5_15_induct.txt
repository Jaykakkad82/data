Namespace(dataset='citeseer', epochs=400, gpu_id=0, hidden=256, inductive=1, keep_ratio=1.0, lr=0.01, method='kmeans', nlayers=2, normalize_features=True, reduction_rate=0.5, save=1, seed=15, weight_decay=0.0005)
size of adj_train: (120, 120)
#edges in adj_train: 16.0
Test set results: loss= 0.8400 accuracy= 0.7860
idx_selected :  [38, 50, 0, 98, 105, 15, 8, 35, 100, 6, 81, 103, 99, 95, 104, 46, 45, 72, 43, 65, 54, 93, 63, 22, 52, 73, 44, 2, 26, 90, 113, 110, 101, 85, 76, 7, 115, 107, 114, 106, 59, 79, 30, 14, 12, 16, 31, 34, 60, 75, 28, 18, 83, 68, 84, 86, 97, 17, 47, 70]
Mean accuracy: [0.6457, 0.007563729238940281]
Namespace(dataset='citeseer', epochs=400, gpu_id=0, hidden=256, inductive=1, keep_ratio=1.0, lr=0.01, method='kmeans', nlayers=2, normalize_features=True, reduction_rate=0.5, save=1, seed=15, weight_decay=0.0005)
size of adj_train: (120, 120)
#edges in adj_train: 16.0
Test set results: loss= 0.8400 accuracy= 0.7860
idx_selected :  [38, 50, 0, 98, 105, 15, 8, 35, 100, 6, 81, 103, 99, 95, 104, 46, 45, 72, 43, 65, 54, 93, 63, 22, 52, 73, 44, 2, 26, 90, 113, 110, 101, 85, 76, 7, 115, 107, 114, 106, 59, 79, 30, 14, 12, 16, 31, 34, 60, 75, 28, 18, 83, 68, 84, 86, 97, 17, 47, 70]
Mean accuracy: [0.6457, 0.007563729238940281]
