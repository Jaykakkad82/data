Namespace(dataset='flickr', dropout=0.0, epochs=400, gpu_id=0, hidden=256, inductive=1, keep_ratio=1.0, lr=0.01, method='kmeans', mlp=0, nlayers=2, normalize_features=True, reduction_rate=0.01, save=True, seed=15, weight_decay=0.005)
size of adj_train: (44625, 44625)
#edges in adj_train: 218140
Test set results: loss= 1.5456 accuracy= 0.4714
Namespace(dataset='flickr', dropout=0.0, epochs=400, gpu_id=0, hidden=256, inductive=1, keep_ratio=1.0, lr=0.01, method='kmeans', mlp=0, nlayers=2, normalize_features=True, reduction_rate=0.01, save=True, seed=15, weight_decay=0.005)
size of adj_train: (44625, 44625)
#edges in adj_train: 218140
Test set results: loss= 1.5456 accuracy= 0.4714
idx_selected :  [7554, 20297, 13301, 24294, 23179, 26335, 192, 36974, 31381, 24453, 14228, 19153, 7498, 22263, 27708, 41081, 5103, 1064, 18788, 28432, 25936, 3980, 23011, 43310, 2982, 25192, 39420, 22161, 2605, 19873, 1846, 32517, 32349, 36048, 40815, 11477, 4218, 22063, 24749, 34322, 11537, 16370, 35092, 5968, 21746, 40257, 31348, 44100, 6686, 35065, 2711, 42045, 18127, 32721, 30173, 19136, 25829, 2426, 7512, 326, 10424, 16501, 11879, 30102, 30800, 38847, 18533, 15020, 867, 1335, 24440, 33085, 40398, 37792, 10456, 40595, 18876, 28358, 328, 9210, 26490, 44390, 2288, 15130, 26739, 38616, 11449, 25355, 35162, 18624, 38314, 36365, 23499, 18307, 946, 27973, 14798, 14508, 12762, 18742, 29367, 26443, 36057, 40898, 26390, 21715, 15251, 12470, 6523, 13906, 33300, 26433, 31789, 8832, 19734, 41976, 42152, 38849, 37675, 32308, 39630, 12695, 18288, 8175, 24601, 15084, 16621, 16361, 19431, 22999, 42813, 6858, 27957, 12555, 10993, 19723, 31248, 1101, 1468, 22554, 32924, 1114, 40198, 33352, 40944, 39449, 27868, 11397, 30006, 34211, 6881, 5674, 23361, 39685, 16397, 32032, 24672, 32441, 43151, 13933, 20500, 41140, 24561, 2651, 17983, 43053, 2596, 24972, 34597, 420, 39062, 3259, 34871, 12704, 19658, 8892, 22343, 3647, 26794, 9878, 43476, 1264, 17266, 23202, 10214, 10579, 22730, 10844, 23831, 8657, 20058, 3806, 28521, 39509, 3370, 37244, 26088, 24700, 13115, 16139, 44332, 17278, 42407, 12408, 5281, 38349, 28490, 27245, 12892, 24649, 4806, 42010, 21784, 22112, 20343, 3883, 22069, 31326, 13682, 6092, 5950, 1407, 15496, 38025, 19863, 37969, 25709, 22220, 15833, 13664, 28907, 42286, 34050, 21864, 13207, 26010, 30425, 12210, 4261, 26135, 13283, 40298, 37991, 36446, 29551, 24536, 19671, 41255, 41336, 42712, 40903, 34874, 29836, 8025, 15512, 11338, 29416, 12336, 3314, 34826, 8291, 5799, 36312, 27185, 1352, 13721, 44078, 42901, 15232, 20372, 33118, 16522, 39424, 11331, 18839, 31993, 23939, 33429, 9041, 43891, 32718, 16850, 28603, 14295, 17370, 28722, 9136, 8997, 2853, 23279, 1762, 2820, 37398, 40231, 38400, 40965, 10850, 9767, 39465, 33070, 5675, 12933, 198, 26488, 41490, 36116, 32270, 2097, 10605, 8396, 25170, 6802, 36496, 35201, 27598, 23545, 22128, 5410, 11470, 27307, 11679, 3092, 20542, 23357, 7067, 43437, 27457, 34460, 10049, 28597, 10682, 33779, 40323, 18138, 19547, 23257, 44058, 38208, 32376, 36705, 33031, 34913, 21561, 6953, 30930, 36794, 44226, 39786, 36119, 6731, 39381, 16878, 22225, 40876, 10639, 44402, 28688, 44177, 38424, 16108, 20574, 1953, 10403, 37303, 34910, 36164, 4294, 30915, 21321, 15711, 39341, 40122, 1055, 38105, 19492, 12955, 40332, 3979, 17390, 15386, 40396, 9799, 15667, 27640, 28599, 12499, 30748, 23750, 19194, 8303, 8486, 5716, 15544, 23946, 15141, 14418, 10050, 723, 102, 40489, 3802, 31292, 7035, 26461, 38340, 21522, 2797, 6499, 13631, 29218, 9259, 7248, 25714, 13736, 4883, 41030, 23720, 24641, 34548, 19768, 32180, 4268, 25982, 4019, 34940, 27108, 18866, 12458, 11917, 9770, 30219, 34030, 43528, 31266, 9905, 13618, 5082, 25763, 23467, 27918, 10070, 25237, 3562, 2167, 3475, 29997]
shape of feat_train: (446, 500)
Mean accuracy: [0.44672612378434096, 0.005176375932841595]
Namespace(dataset='flickr', dropout=0.0, epochs=400, gpu_id=0, hidden=256, inductive=1, keep_ratio=1.0, lr=0.01, method='kmeans', mlp=0, nlayers=2, normalize_features=True, reduction_rate=0.01, save=True, seed=15, weight_decay=0.005)
size of adj_train: (44625, 44625)
#edges in adj_train: 218140
Test set results: loss= 1.5456 accuracy= 0.4714
idx_selected :  [7554, 20297, 13301, 24294, 23179, 26335, 192, 36974, 31381, 24453, 14228, 19153, 7498, 22263, 27708, 41081, 5103, 1064, 18788, 28432, 25936, 3980, 23011, 43310, 2982, 25192, 39420, 22161, 2605, 19873, 1846, 32517, 32349, 36048, 40815, 11477, 4218, 22063, 24749, 34322, 11537, 16370, 35092, 5968, 21746, 40257, 31348, 44100, 6686, 35065, 2711, 42045, 18127, 32721, 30173, 19136, 25829, 2426, 7512, 326, 10424, 16501, 11879, 30102, 30800, 38847, 18533, 15020, 867, 1335, 24440, 33085, 40398, 37792, 10456, 40595, 18876, 28358, 328, 9210, 26490, 44390, 2288, 15130, 26739, 38616, 11449, 25355, 35162, 18624, 38314, 36365, 23499, 18307, 946, 27973, 14798, 14508, 12762, 18742, 29367, 26443, 36057, 40898, 26390, 21715, 15251, 12470, 6523, 13906, 33300, 26433, 31789, 8832, 19734, 41976, 42152, 38849, 37675, 32308, 39630, 12695, 18288, 8175, 24601, 15084, 16621, 16361, 19431, 22999, 42813, 6858, 27957, 12555, 10993, 19723, 31248, 1101, 1468, 22554, 32924, 1114, 40198, 33352, 40944, 39449, 27868, 11397, 30006, 34211, 6881, 5674, 23361, 39685, 16397, 32032, 24672, 32441, 43151, 13933, 20500, 41140, 24561, 2651, 17983, 43053, 2596, 24972, 34597, 420, 39062, 3259, 34871, 12704, 19658, 8892, 22343, 3647, 26794, 9878, 43476, 1264, 17266, 23202, 10214, 10579, 22730, 10844, 23831, 8657, 20058, 3806, 28521, 39509, 3370, 37244, 26088, 24700, 13115, 16139, 44332, 17278, 42407, 12408, 5281, 38349, 28490, 27245, 12892, 24649, 4806, 42010, 21784, 22112, 20343, 3883, 22069, 31326, 13682, 6092, 5950, 1407, 15496, 38025, 19863, 37969, 25709, 22220, 15833, 13664, 28907, 42286, 34050, 21864, 13207, 26010, 30425, 12210, 4261, 26135, 13283, 40298, 37991, 36446, 29551, 24536, 19671, 41255, 41336, 42712, 40903, 34874, 29836, 8025, 15512, 11338, 29416, 12336, 3314, 34826, 8291, 5799, 36312, 27185, 1352, 13721, 44078, 42901, 15232, 20372, 33118, 16522, 39424, 11331, 18839, 31993, 23939, 33429, 9041, 43891, 32718, 16850, 28603, 14295, 17370, 28722, 9136, 8997, 2853, 23279, 1762, 2820, 37398, 40231, 38400, 40965, 10850, 9767, 39465, 33070, 5675, 31828, 198, 26488, 41490, 36116, 32270, 2097, 10605, 8396, 25170, 6802, 36496, 35201, 27598, 23545, 22128, 5410, 11470, 27307, 11679, 3092, 20542, 23357, 7067, 43437, 27457, 34460, 10049, 28597, 10682, 33779, 40323, 18138, 19547, 23257, 44058, 38208, 32376, 36705, 33031, 34913, 21561, 6953, 30930, 36794, 44226, 39786, 36119, 6731, 39381, 16878, 22225, 40876, 10639, 44402, 28688, 44177, 38424, 16108, 20574, 1953, 10403, 37303, 34910, 36164, 4294, 30915, 21321, 15711, 39341, 40122, 1055, 38105, 19492, 12955, 40332, 3979, 17390, 15386, 40396, 9799, 15667, 27640, 28599, 12499, 30748, 23750, 19194, 8303, 8486, 5716, 15544, 23946, 15141, 42967, 10050, 723, 102, 40489, 3802, 31292, 7035, 26461, 38340, 21522, 2797, 6499, 13631, 29218, 9259, 7248, 25714, 13736, 4883, 41030, 23720, 24641, 13818, 19768, 32180, 33502, 25982, 4019, 34940, 27108, 18866, 12458, 11917, 9770, 30219, 34030, 43528, 31266, 9905, 13618, 5082, 25763, 23467, 27918, 10070, 25237, 3562, 2167, 3475, 29997]
shape of feat_train: (446, 500)
Mean accuracy: [0.4463227714785103, 0.005318347023826005]
