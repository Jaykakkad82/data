# -*- coding: utf-8 -*-
"""Exp2_Explaination_comparison.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LwAiwNw8WbPtFXC5uGXAE30d3BAhWaJy
"""

# from google.colab import drive
# drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/MyDrive/Exp2
# %pwd

import os
import torch
os.environ['TORCH'] = torch.__version__
print(torch.__version__)
# !pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.1.0+cu118.html

# !pip install torch_geometric

import torch_geometric

class arguments:
  def __init__(self, seed = 10):
    self.seed = seed

args = arguments()

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

import torch_geometric
import os.path as osp

import torch
import torch.nn.functional as F

from torch_geometric.datasets import Planetoid
from torch_geometric.explain import Explainer, GNNExplainer
from torch_geometric.nn import GCNConv

import random

import torch
from torch_geometric.explain import Explainer, GNNExplainer
from torch_geometric.data import DataLoader
from torch_geometric.datasets import Planetoid
import networkx as nx
from sklearn.metrics import pairwise_distances

from sklearn.metrics import jaccard_score
from sklearn.metrics import pairwise_distances
from scipy.stats import wasserstein_distance, entropy
import numpy as np
import pandas as pd


from scipy.stats import wasserstein_distance, entropy
import numpy as np
import pandas as pd

from scipy.stats import wasserstein_distance, entropy
import numpy as np
import pandas as pd

from torch_geometric.utils import to_dense_adj
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch_geometric.nn import GCNConv, global_mean_pool

# seeds
# random seed setting
# random.seed(args.seed)
# np.random.seed(args.seed)
# torch.manual_seed(args.seed)
# torch.cuda.manual_seed(args.seed)

# model that we will use to load the weights
class GCNLayer(nn.Module):
    def __init__(self, in_channels, out_channels, with_bias=True):
        super(GCNLayer, self).__init__()
        self.conv = GCNConv(in_channels, out_channels, bias=with_bias)

    def forward(self, x, edge_index):
        x = self.conv(x, edge_index)
        return F.relu(x)

class GCNModel(nn.Module):
    def __init__(self, num_features, hidden_channels, num_classes, num_layers=2,
                 dropout=0.5, with_bn=False):
        super(GCNModel, self).__init__()

        self.layers = nn.ModuleList([])
        self.num_layers = num_layers

        if with_bn:
            self.bns = nn.ModuleList([])

        # Input layer
        self.layers.append(GCNLayer(num_features, hidden_channels))
        if with_bn:
            self.bns.append(nn.BatchNorm1d(hidden_channels))

        # Hidden layers
        for _ in range(num_layers - 2):
            self.layers.append(GCNLayer(hidden_channels, hidden_channels))
            if with_bn:
                self.bns.append(nn.BatchNorm1d(hidden_channels))

        # Output layer
        self.layers.append(GCNLayer(hidden_channels, num_classes))

        self.dropout = dropout
        self.with_bn = with_bn

    def forward(self, x, edge_index):
        for i, layer in enumerate(self.layers):
            x = layer(x, edge_index)
            if i != self.num_layers - 1:
                x = self.bns[i](x) if self.with_bn else x
                x = F.relu(x)
                x = F.dropout(x, p=self.dropout, training=self.training)

        return F.log_softmax(x, dim=1)

# training a Full model for Cora and Citeseer - Storing the weights - Can be done in a different file too

class Explanations:
    def __init__(self, model1, model2, dataset, nodes_to_explain, threshold_val):
        self.model1 = model1.to(device)
        self.model2 = model2.to(device)
        self.dataset_name = dataset
        self.nodes_to_explain = nodes_to_explain
        self.data = self.load_data().to(device)
        self.explanations1 = {}
        self.explanations2 = {}
        self.threshold_val = threshold_val

    def load_data(self):
        if self.dataset_name == 'cora':
            dataset = Planetoid(root='data/Cora', name='Cora')
        elif self.dataset_name == 'citeseer':
            dataset = Planetoid(root='data/CiteSeer', name='CiteSeer')
        else:
            raise ValueError("Invalid dataset name. Supported datasets: 'cora', 'citeseer'")
        return dataset[0]

    def generate_explanation(self, node_index):
        explainer1 = Explainer(
            model=self.model1,
            algorithm=GNNExplainer(epochs=200),
            explanation_type='model',
            node_mask_type='object',
            edge_mask_type='object',
            model_config=dict(
                mode='multiclass_classification',
                task_level='node',
                return_type='log_probs',
            ),
            threshold_config = dict(threshold_type = 'topk', value = self.threshold_val)
        )

        explainer2 = Explainer(
            model=self.model2,
            algorithm=GNNExplainer(epochs=200),
            explanation_type='model',
            node_mask_type='object',
            edge_mask_type='object',
            model_config=dict(
                mode='multiclass_classification',
                task_level='node',
                return_type='log_probs',
            ),
            threshold_config = dict(threshold_type = 'topk', value = self.threshold_val)
        )

        explanation1 = explainer1(self.data.x, self.data.edge_index, index=node_index)
        explanation2 = explainer2(self.data.x, self.data.edge_index, index=node_index)

        # print(explanation1)
        # explanation1.visualize_graph()
        # explanation2.visualize_graph()
        # print("sizes of nodemask, edgemask",explanation1.node_mask.size(),explanation1.edge_mask.size() )

        self.explanations1[node_index] = explanation1
        self.explanations2[node_index] = explanation2

    def jaccard_similarity(self, explanation1, explanation2):
      # Step 1: Extract node and edge sets from the masks
      nodes_set1 = set(explanation1.node_mask.nonzero().flatten().tolist())
      edges_set1 = set(explanation1.edge_mask.nonzero().flatten().tolist())

      nodes_set2 = set(explanation2.node_mask.nonzero().flatten().tolist())
      edges_set2 = set(explanation2.edge_mask.nonzero().flatten().tolist())
      # print("Node Sets of explanation", nodes_set1,nodes_set2)
      # print("edge sets of explanation", edges_set1,edges_set2)

      # Step 2: Calculate Jaccard Similarity
      if len(nodes_set1.union(nodes_set2))==0:
        jaccard_similarity_nodes =0
      else:
        jaccard_similarity_nodes = len(nodes_set1.intersection(nodes_set2)) / len(nodes_set1.union(nodes_set2))

      if len(edges_set1.union(edges_set2))==0:
        jaccard_similarity_edges = 0
      else:
        jaccard_similarity_edges= len(edges_set1.intersection(edges_set2)) / len(edges_set1.union(edges_set2))

      return jaccard_similarity_nodes, jaccard_similarity_edges

    def cosine_similarity(self, explanation1, explanation2):
        # Step 1: Flatten the node and edge masks
        node_mask1 = explanation1.node_mask.view(-1)
        edge_mask1 = explanation1.edge_mask.view(-1)

        node_mask2 = explanation2.node_mask.view(-1)
        edge_mask2 = explanation2.edge_mask.view(-1)

        # Step 2: Concatenate the flattened masks into vectors
        vector1 = torch.cat((node_mask1, edge_mask1))
        vector2 = torch.cat((node_mask2, edge_mask2))

        # print("vector_size",vector1.size())

        # Step 3: Calculate cosine similarity
        similarity = F.cosine_similarity(vector1, vector2, dim=0)

        return similarity.item()

    def compare_explanations(self, node_index):
        # print("self.ex1", self.explanations1)
        # print("self.ex2", self.explanations2)
        # print(f"============comparing explanatin for {node_index} ================")
        explanation1 = self.explanations1[node_index]
        explanation2 = self.explanations2[node_index]

        jaccard_similarity_nodes, jaccard_similarity_edges = self.jaccard_similarity(explanation1, explanation2)
        cosine_similarity = self.cosine_similarity(explanation1, explanation2)
        del self.explanations1[node_index]
        del self.explanations2[node_index]
        return jaccard_similarity_nodes, jaccard_similarity_edges, cosine_similarity

    def run_comparison(self):
        results = {'jaccard_similarity_nodes': [], 'jaccard_similarity_edges': [], 'cosine_similarity': []}

        for node_index in self.nodes_to_explain:
            self.generate_explanation(node_index)
            jaccard_similarity_nodes, jaccard_similarity_edges, cosine_similarity = self.compare_explanations(node_index)

            results['jaccard_similarity_nodes'].append(jaccard_similarity_nodes)
            results['jaccard_similarity_edges'].append(jaccard_similarity_edges)
            results['cosine_similarity'].append(cosine_similarity)


        #df = pd.DataFrame(results)
        return results


class experiment2():
  def __init__(self, cora_data, citeseer_data, args, seedlist, sample_per_seed, explanation_threshold_list, model_cora_bench, model_citeseer_bench):
    self.args = args
    self.seeds = {}
    self.sample_per_seed = sample_per_seed
    self.seedlist = seedlist
    self.cora = cora_data
    self.citeseer = citeseer_data
    self.threshold_list = explanation_threshold_list
    self.seeds["cora"] = self.generate_random_testset(self.cora,seedlist, sample_per_seed)
    self.seeds["citeseer"] = self.generate_random_testset(self.citeseer,seedlist, sample_per_seed)
    self.model_cora_bechmark = model_cora_bench
    self.model_citeseer_bechmark = model_citeseer_bench
    self.out = {} # method : {threshold: {seeds: meanvalue}}

    self.results_store = datastorage(self.threshold_list)
    self.iter=0


  def generate_random_testset(self, data, seedlist,samplesize):
    indices = torch.nonzero(data.test_mask).squeeze().tolist()
    out = {}
    for aseed in seedlist:
      np.random.seed(aseed)
      alist = np.random.choice(indices, size=samplesize)
      out[aseed] = alist

    return out

  def load_model_method(self,path, dataname = "cora"):
    '''creates a gcn_model and loads the weights and returns a loaded model'''
      # Create an instance of the GCNModel
    if dataname == 'cora':
      gcn_model = GCNModel(num_features = 1433, hidden_channels = 256, num_classes = 7, num_layers = 2, dropout=0.5, with_bn = False)
    elif dataname == "citeseer":
      gcn_model = GCNModel(num_features = 3703, hidden_channels = 256, num_classes = 6, num_layers = 2, dropout=0.5, with_bn = False)
    state_dict = torch.load(path)
    for key in list(state_dict.keys()):
        if key == 'layers.0.weight':
          newkey = 'layers.0.conv.lin.weight'
          state_dict[newkey] = state_dict.pop(key)
          state_dict[newkey] = state_dict[newkey].T
        elif key == 'layers.0.bias':
          newkey = 'layers.0.conv.bias'
          state_dict[newkey] = state_dict.pop(key)
        elif key == 'layers.1.weight':
          newkey = 'layers.1.conv.lin.weight'
          state_dict[newkey] = state_dict.pop(key)
          state_dict[newkey] = state_dict[newkey].T
        elif key == 'layers.1.bias':
          newkey = 'layers.1.conv.bias'
          state_dict[newkey] = state_dict.pop(key)

    gcn_model.load_state_dict(state_dict)
    return gcn_model

  def run_experiment(self, pathlist):

    # load the model
    for key, value in pathlist.items():
      dataname,method,compression,model_seed = key
      path = value
      # collect all nodes for different seeds
      nodes_to_explain = []
      for aseed in self.seedlist:
        nodes_to_explain.extend(self.seeds[dataname][aseed].tolist())

      #for path in paths:
        #path = ("/content/sample_data/model_cora_0.5_1_trans.pt")
      gcn_model = self.load_model_method(path, dataname)
      print(path)

      for thresh in self.threshold_list:
        if dataname =="cora":
          #print("Cora nodes: ", nodes_to_explain, "Threshold", thresh )
          #nodes_to_explain = self.seeds[dataname][aseed]
          explanations = Explanations(self.model_cora_bechmark, gcn_model, 'cora', nodes_to_explain,thresh)
          results = explanations.run_comparison()
          # print("Cora ==> ", results)
          self.store(results,[dataname, method, compression, model_seed, thresh])
        elif dataname == "citeseer":
          # print("Citeseer nodes: ", nodes_to_explain, "Threshold", thresh )
          # nodes_to_explain = self.seeds[dataname][aseed]
          explanations = Explanations(self.model_citeseer_bechmark, gcn_model, 'citeseer', nodes_to_explain,thresh)
          results = explanations.run_comparison()
          # print("Citeseer ==> ", results)
          self.store(results,[dataname, method, compression, model_seed, thresh])

  def store(self,results,details):
    # details data structure : (dataset/method/compression/seed)
    self.iter +=1
    self.results_store.update(results,details)
    if self.iter%6==0:
       self.results_store.display_save()

import pandas as pd
class datastorage():
  def __init__(self, theshold_list):
    self.methods = ["random","herding","kcenter","kmeans", "gcond","sfgc", "one-step"]
    self.threshold = theshold_list
    self.data = ["cora", "citeseer"]
    self.compression =  [0.125,0.25,0.5]

    # create tables 3seeds - 1,15,85 x 3metrics - Jac_node, Jac_edge, cosine
    self.jac_node_1 = self.create_table()
    self.jac_node_15 = self.create_table()
    self.jac_node_85 = self.create_table()

    self.jac_edge_1 = self.create_table()
    self.jac_edge_15 = self.create_table()
    self.jac_edge_85 = self.create_table()

    self.cosine_1 = self.create_table()
    self.cosine_15 = self.create_table()
    self.cosine_85 = self.create_table()


  def create_table(self):
    col_idx = pd.MultiIndex.from_product([self.methods,self.threshold],names = ["methods","threshold"])
    row_idx = pd.MultiIndex.from_product([self.data,self.compression],names = ["Dataset","Compression ratio"])
    df = pd.DataFrame(columns=col_idx, index=row_idx)
    df = df.fillna(0)
    return df

  def update(self, results, details):
    # details datastructure : (dataset/method/compression/seed)
    # print("results - ", results)
    dataset, method, compression, seed, threshold = details
    # print("Keys", (dataset, compression), (method, threshold))
    # print("Shape of mean",np.mean(results["jaccard_similarity_nodes"]).shape)
    #print("Shape of jacard",self.jac_node_1.loc[(dataset, compression), (method, threshold)])

    if seed==1:
      self.jac_node_1.loc[(dataset,compression),(method,threshold)] = np.mean(results["jaccard_similarity_nodes"])
      self.jac_edge_1.loc[(dataset,compression),(method,threshold)] = np.mean(results["jaccard_similarity_edges"])
      self.cosine_1.loc[(dataset,compression),(method,threshold)] = np.mean(results["cosine_similarity"])

    if seed==15:
      self.jac_node_15.loc[(dataset,compression),(method,threshold)] = np.mean(results["jaccard_similarity_nodes"])
      self.jac_edge_15.loc[(dataset,compression),(method,threshold)] = np.mean(results["jaccard_similarity_edges"])
      self.cosine_15.loc[(dataset,compression),(method,threshold)] = np.mean(results["cosine_similarity"])

    if seed == 85:
      self.jac_node_85.loc[(dataset,compression),(method,threshold)] = np.mean(results["jaccard_similarity_nodes"])
      self.jac_edge_85.loc[(dataset,compression),(method,threshold)] = np.mean(results["jaccard_similarity_edges"])
      self.cosine_85.loc[(dataset,compression),(method,threshold)] = np.mean(results["cosine_similarity"])

  def display_save(self):
    # Create a new dataframe 'average' for jacard nodes
    average_jac_nodes = self.create_table()
    for col in average_jac_nodes.columns:
      average_jac_nodes[col] = (self.jac_node_1[col] + self.jac_node_15[col] + self.jac_node_85[col]) / 3

    # Create a new dataframe 'average' for jacard edges
    average_jac_edges = self.create_table()
    for col in average_jac_edges.columns:
      average_jac_edges[col] = (self.jac_edge_1[col] + self.jac_edge_15[col] + self.jac_edge_85[col]) / 3

    # Create a new dataframe 'average' for cosine
    average_cosine = self.create_table()
    for col in average_cosine.columns:
      average_cosine[col] = (self.cosine_1[col] + self.cosine_15[col] + self.cosine_85[col]) / 3

    # print("Jacard Nodes Similarity")
    # print(average_jac_nodes)
    average_jac_nodes.to_csv("Avg_Jacard_nodes_similarity")
    # print("Jacard Edges Similarity")
    # print(average_jac_edges)
    average_jac_edges.to_csv("Avg_Jacard_edges_similarity")
    # print("Cosine Similarity - Overall")
    # print(average_cosine)
    average_cosine.to_csv("Avg_Cosine_similarity")

    output_folder = 'rawFiles'
    os.makedirs(output_folder, exist_ok=True)
    self.jac_node_1.to_csv("rawFiles/jac_node_1")
    self.jac_node_15.to_csv("rawFiles/jac_node_15")
    self.jac_node_85.to_csv("rawFiles/jac_node_85")

    self.jac_edge_1.to_csv("rawFiles/jac_edge_1")
    self.jac_edge_15.to_csv("rawFiles/jac_edge_15")
    self.jac_edge_85.to_csv("rawFiles/jac_edge_85")

    self.cosine_1.to_csv("rawFiles/cosine_1")
    self.cosine_15.to_csv("rawFiles/cosine_15")
    self.cosine_85.to_csv("rawFiles/cosine_85")


# ## =========================== MAIN PROGRAM ====================================================================================

# load data
dataset = Planetoid(root='data', name= "cora")
cora_data = dataset[0]
dataset = Planetoid(root='data', name= "citeseer")
citeseer_data = dataset[0]

# Experiment parameters
seedlist = [1,85,105]
sample_per_seed = 10
explanation_threshold_list = [5,10,15]

# load bench - cora
model_cora_bench = GCNModel(num_features = 1433, hidden_channels = 256, num_classes = 7, num_layers = 2, dropout=0.5, with_bn = False)
state_dict = torch.load("bechmark_models/model_cora.pt")
model_cora_bench.load_state_dict(state_dict)

# load bench - citeseer
model_citeseer_bench = GCNModel(num_features = 3703, hidden_channels = 256, num_classes = 6, num_layers = 2, dropout=0.5, with_bn = False)
state_dict = torch.load("bechmark_models/model_citeseer.pt")
model_citeseer_bench.load_state_dict(state_dict)

exp = experiment2(cora_data, citeseer_data, args, seedlist, sample_per_seed, explanation_threshold_list, model_cora_bench, model_citeseer_bench)


#dataname,method,compression,model_seed
pathlist = {('citeseer', 'herding', 0.125, 15): 'models_selection/herding/model__herding_citeseer_0.125_15_trans.pt', ('citeseer', 'herding', 0.125, 1): 'models_selection/herding/model__herding_citeseer_0.125_1_trans.pt', ('citeseer', 'herding', 0.125, 85): 'models_selection/herding/model__herding_citeseer_0.125_85_trans.pt', ('citeseer', 'herding', 0.25, 15): 'models_selection/herding/model__herding_citeseer_0.25_15_trans.pt', ('citeseer', 'herding', 0.25, 1): 'models_selection/herding/model__herding_citeseer_0.25_1_trans.pt', ('citeseer', 'herding', 0.25, 85): 'models_selection/herding/model__herding_citeseer_0.25_85_trans.pt', ('citeseer', 'herding', 0.5, 15): 'models_selection/herding/model__herding_citeseer_0.5_15_trans.pt', ('citeseer', 'herding', 0.5, 1): 'models_selection/herding/model__herding_citeseer_0.5_1_trans.pt', ('citeseer', 'herding', 0.5, 85): 'models_selection/herding/model__herding_citeseer_0.5_85_trans.pt', ('cora', 'herding', 0.125, 15): 'models_selection/herding/model__herding_cora_0.125_15_trans.pt', ('cora', 'herding', 0.125, 1): 'models_selection/herding/model__herding_cora_0.125_1_trans.pt', ('cora', 'herding', 0.125, 85): 'models_selection/herding/model__herding_cora_0.125_85_trans.pt', ('cora', 'herding', 0.25, 15): 'models_selection/herding/model__herding_cora_0.25_15_trans.pt', ('cora', 'herding', 0.25, 1): 'models_selection/herding/model__herding_cora_0.25_1_trans.pt', ('cora', 'herding', 0.25, 85): 'models_selection/herding/model__herding_cora_0.25_85_trans.pt', ('cora', 'herding', 0.5, 15): 'models_selection/herding/model__herding_cora_0.5_15_trans.pt', ('cora', 'herding', 0.5, 1): 'models_selection/herding/model__herding_cora_0.5_1_trans.pt', ('cora', 'herding', 0.5, 85): 'models_selection/herding/model__herding_cora_0.5_85_trans.pt',
            ('citeseer', 'kcenter', 0.125, 15): 'models_selection/kcenter/model__kcenter_citeseer_0.125_15_trans.pt', ('citeseer', 'kcenter', 0.125, 1): 'models_selection/kcenter/model__kcenter_citeseer_0.125_1_trans.pt', ('citeseer', 'kcenter', 0.125, 85): 'models_selection/kcenter/model__kcenter_citeseer_0.125_85_trans.pt', ('citeseer', 'kcenter', 0.25, 15): 'models_selection/kcenter/model__kcenter_citeseer_0.25_15_trans.pt', ('citeseer', 'kcenter', 0.25, 1): 'models_selection/kcenter/model__kcenter_citeseer_0.25_1_trans.pt', ('citeseer', 'kcenter', 0.25, 85): 'models_selection/kcenter/model__kcenter_citeseer_0.25_85_trans.pt', ('citeseer', 'kcenter', 0.5, 15): 'models_selection/kcenter/model__kcenter_citeseer_0.5_15_trans.pt', ('citeseer', 'kcenter', 0.5, 1): 'models_selection/kcenter/model__kcenter_citeseer_0.5_1_trans.pt', ('citeseer', 'kcenter', 0.5, 85): 'models_selection/kcenter/model__kcenter_citeseer_0.5_85_trans.pt', ('cora', 'kcenter', 0.125, 15): 'models_selection/kcenter/model__kcenter_cora_0.125_15_trans.pt', ('cora', 'kcenter', 0.125, 1): 'models_selection/kcenter/model__kcenter_cora_0.125_1_trans.pt', ('cora', 'kcenter', 0.125, 85): 'models_selection/kcenter/model__kcenter_cora_0.125_85_trans.pt', ('cora', 'kcenter', 0.25, 15): 'models_selection/kcenter/model__kcenter_cora_0.25_15_trans.pt', ('cora', 'kcenter', 0.25, 1): 'models_selection/kcenter/model__kcenter_cora_0.25_1_trans.pt', ('cora', 'kcenter', 0.25, 85): 'models_selection/kcenter/model__kcenter_cora_0.25_85_trans.pt', ('cora', 'kcenter', 0.5, 15): 'models_selection/kcenter/model__kcenter_cora_0.5_15_trans.pt', ('cora', 'kcenter', 0.5, 1): 'models_selection/kcenter/model__kcenter_cora_0.5_1_trans.pt', ('cora', 'kcenter', 0.5, 85): 'models_selection/kcenter/model__kcenter_cora_0.5_85_trans.pt',
            ('citeseer', 'kmeans', 0.125, 15): 'models_selection/kmeans/model__kmeans_citeseer_0.125_15_trans.pt', ('citeseer', 'kmeans', 0.125, 1): 'models_selection/kmeans/model__kmeans_citeseer_0.125_1_trans.pt', ('citeseer', 'kmeans', 0.125, 85): 'models_selection/kmeans/model__kmeans_citeseer_0.125_85_trans.pt', ('citeseer', 'kmeans', 0.25, 15): 'models_selection/kmeans/model__kmeans_citeseer_0.25_15_trans.pt', ('citeseer', 'kmeans', 0.25, 1): 'models_selection/kmeans/model__kmeans_citeseer_0.25_1_trans.pt', ('citeseer', 'kmeans', 0.25, 85): 'models_selection/kmeans/model__kmeans_citeseer_0.25_85_trans.pt', ('citeseer', 'kmeans', 0.5, 15): 'models_selection/kmeans/model__kmeans_citeseer_0.5_15_trans.pt', ('citeseer', 'kmeans', 0.5, 1): 'models_selection/kmeans/model__kmeans_citeseer_0.5_1_trans.pt', ('citeseer', 'kmeans', 0.5, 85): 'models_selection/kmeans/model__kmeans_citeseer_0.5_85_trans.pt', ('cora', 'kmeans', 0.125, 15): 'models_selection/kmeans/model__kmeans_cora_0.125_15_trans.pt', ('cora', 'kmeans', 0.125, 1): 'models_selection/kmeans/model__kmeans_cora_0.125_1_trans.pt', ('cora', 'kmeans', 0.125, 85): 'models_selection/kmeans/model__kmeans_cora_0.125_85_trans.pt', ('cora', 'kmeans', 0.25, 15): 'models_selection/kmeans/model__kmeans_cora_0.25_15_trans.pt', ('cora', 'kmeans', 0.25, 1): 'models_selection/kmeans/model__kmeans_cora_0.25_1_trans.pt', ('cora', 'kmeans', 0.25, 85): 'models_selection/kmeans/model__kmeans_cora_0.25_85_trans.pt', ('cora', 'kmeans', 0.5, 15): 'models_selection/kmeans/model__kmeans_cora_0.5_15_trans.pt', ('cora', 'kmeans', 0.5, 1): 'models_selection/kmeans/model__kmeans_cora_0.5_1_trans.pt', ('cora', 'kmeans', 0.5, 85): 'models_selection/kmeans/model__kmeans_cora_0.5_85_trans.pt',
            ('citeseer', 'random', 0.125, 15): 'models_selection/random/model__random_citeseer_0.125_15_trans.pt', ('citeseer', 'random', 0.125, 1): 'models_selection/random/model__random_citeseer_0.125_1_trans.pt', ('citeseer', 'random', 0.125, 85): 'models_selection/random/model__random_citeseer_0.125_85_trans.pt', ('citeseer', 'random', 0.25, 15): 'models_selection/random/model__random_citeseer_0.25_15_trans.pt', ('citeseer', 'random', 0.25, 1): 'models_selection/random/model__random_citeseer_0.25_1_trans.pt', ('citeseer', 'random', 0.25, 85): 'models_selection/random/model__random_citeseer_0.25_85_trans.pt', ('citeseer', 'random', 0.5, 15): 'models_selection/random/model__random_citeseer_0.5_15_trans.pt', ('citeseer', 'random', 0.5, 1): 'models_selection/random/model__random_citeseer_0.5_1_trans.pt', ('citeseer', 'random', 0.5, 85): 'models_selection/random/model__random_citeseer_0.5_85_trans.pt', ('cora', 'random', 0.125, 15): 'models_selection/random/model__random_cora_0.125_15_trans.pt', ('cora', 'random', 0.125, 1): 'models_selection/random/model__random_cora_0.125_1_trans.pt', ('cora', 'random', 0.125, 85): 'models_selection/random/model__random_cora_0.125_85_trans.pt', ('cora', 'random', 0.25, 15): 'models_selection/random/model__random_cora_0.25_15_trans.pt', ('cora', 'random', 0.25, 1): 'models_selection/random/model__random_cora_0.25_1_trans.pt', ('cora', 'random', 0.25, 85): 'models_selection/random/model__random_cora_0.25_85_trans.pt', ('cora', 'random', 0.5, 15): 'models_selection/random/model__random_cora_0.5_15_trans.pt', ('cora', 'random', 0.5, 1): 'models_selection/random/model__random_cora_0.5_1_trans.pt', ('cora', 'random', 0.5, 85): 'models_selection/random/model__random_cora_0.5_85_trans.pt',
            ('citeseer', 'gcond', 0.125, 15): 'models_distil/gcond/model_citeseer_0.125_15_0_trans.pt', ('citeseer', 'gcond', 0.125, 1): 'models_distil/gcond/model_citeseer_0.125_1__0_trans.pt', ('citeseer', 'gcond', 0.125, 85): 'models_distil/gcond/model_citeseer_0.125_85_0_trans.pt', ('citeseer', 'gcond', 0.25, 15): 'models_distil/gcond/model_citeseer_0.25_15__0_trans.pt', ('citeseer', 'gcond', 0.25, 1): 'models_distil/gcond/model_citeseer_0.25_1__0_trans.pt', ('citeseer', 'gcond', 0.25, 85): 'models_distil/gcond/model_citeseer_0.25_85__0_trans.pt', ('citeseer', 'gcond', 0.5, 15): 'models_distil/gcond/model_citeseer_0.5_15__0_trans.pt', ('citeseer', 'gcond', 0.5, 1): 'models_distil/gcond/model_citeseer_0.5_1__0_trans.pt', ('citeseer', 'gcond', 0.5, 85): 'models_distil/gcond/model_citeseer_0.5_85__0_trans.pt', ('cora', 'gcond', 0.125, 15): 'models_distil/gcond/model_cora_0.125_15_0_trans.pt', ('cora', 'gcond', 0.125, 1): 'models_distil/gcond/model_cora_0.125_1__0_trans.pt', ('cora', 'gcond', 0.125, 85): 'models_distil/gcond/model_cora_0.125_85_0_trans.pt', ('cora', 'gcond', 0.25, 15): 'models_distil/gcond/model_cora_0.25_15__0_trans.pt', ('cora', 'gcond', 0.25, 1): 'models_distil/gcond/model_cora_0.25_1__0_trans.pt', ('cora', 'gcond', 0.25, 85): 'models_distil/gcond/model_cora_0.25_85__0_trans.pt', ('cora', 'gcond', 0.5, 15): 'models_distil/gcond/model_cora_0.5_15__0_trans.pt', ('cora', 'gcond', 0.5, 1): 'models_distil/gcond/model_cora_0.5_1__0_trans.pt', ('cora', 'gcond', 0.5, 85): 'models_distil/gcond/model_cora_0.5_85__0_trans.pt',
            ('citeseer', 'one-step', 0.125, 15): 'models_distil/onestep/model_citeseer_0.125_15__1_trans.pt', ('citeseer', 'one-step', 0.125, 1): 'models_distil/onestep/model_citeseer_0.125_1__1_trans.pt', ('citeseer', 'one-step', 0.125, 85): 'models_distil/onestep/model_citeseer_0.125_85__1_trans.pt', ('citeseer', 'one-step', 0.25, 15): 'models_distil/onestep/model_citeseer_0.25_15__1_trans.pt', ('citeseer', 'one-step', 0.25, 1): 'models_distil/onestep/model_citeseer_0.25_1__1_trans.pt', ('citeseer', 'one-step', 0.25, 85): 'models_distil/onestep/model_citeseer_0.25_85__1_trans.pt', ('citeseer', 'one-step', 0.5, 15): 'models_distil/onestep/model_citeseer_0.5_15__1_trans.pt', ('citeseer', 'one-step', 0.5, 1): 'models_distil/onestep/model_citeseer_0.5_1__1_trans.pt', ('citeseer', 'one-step', 0.5, 85): 'models_distil/onestep/model_citeseer_0.5_85__1_trans.pt', ('cora', 'one-step', 0.125, 15): 'models_distil/onestep/model_cora_0.125_15__1_trans.pt', ('cora', 'one-step', 0.125, 1): 'models_distil/onestep/model_cora_0.125_1__1_trans.pt', ('cora', 'one-step', 0.125, 85): 'models_distil/onestep/model_cora_0.125_85__1_trans.pt', ('cora', 'one-step', 0.25, 15): 'models_distil/onestep/model_cora_0.25_15__1_trans.pt', ('cora', 'one-step', 0.25, 1): 'models_distil/onestep/model_cora_0.25_1__1_trans.pt', ('cora', 'one-step', 0.25, 85): 'models_distil/onestep/model_cora_0.25_85__1_trans.pt', ('cora', 'one-step', 0.5, 15): 'models_distil/onestep/model_cora_0.5_15__1_trans.pt', ('cora', 'one-step', 0.5, 1): 'models_distil/onestep/model_cora_0.5_1__1_trans.pt', ('cora', 'one-step', 0.5, 85): 'models_distil/onestep/model_cora_0.5_85__1_trans.pt'}

# pathlist= {('citeseer','sfgc',0.5,15):"models_distil/sfgc/GCN_eval.pt"}
exp.run_experiment(pathlist)

exp.results_store.display_save()

